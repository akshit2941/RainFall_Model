{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrq3nOstdqdF",
        "outputId": "62f27793-d81c-4df1-b0cc-611494526835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacking Regressor:\n",
            "MSE: 0.00023500050404377335, R^2: 0.9998067737831569, Accuracy: 0.9968148455892536\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load your dataset (ensure 'Rainfall' is the target variable)\n",
        "data = pd.read_csv('Weather_data.csv')\n",
        "\n",
        "# Create a new 'Rainfall' column from 'precip_mm' if it doesn't exist\n",
        "if 'Rainfall' not in data.columns and 'precip_mm' in data.columns:\n",
        "    data['Rainfall'] = data['precip_mm']\n",
        "elif 'Rainfall' not in data.columns:\n",
        "    raise KeyError(\"'Rainfall' column is missing and 'precip_mm' is also not available. Please check the dataset.\")\n",
        "\n",
        "# One-hot encoding for categorical features\n",
        "data = pd.get_dummies(data, drop_first=True)  # Convert categorical variables into dummy/indicator variables\n",
        "\n",
        "# Assuming 'Rainfall' is the target variable\n",
        "X = data.drop(columns=['Rainfall'])  # Features\n",
        "y = data['Rainfall']  # Target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Base models (base learners)\n",
        "base_learners = [\n",
        "    ('rf', RandomForestRegressor(random_state=42)),  # Random Forest\n",
        "    ('gb', GradientBoostingRegressor(random_state=42))  # Gradient Boosting\n",
        "]\n",
        "\n",
        "# Meta-model (Linear Regression in this case)\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Stacking Regressor\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=base_learners,  # List of base learners\n",
        "    final_estimator=meta_model,  # Meta-model\n",
        "    cv=5  # Cross-validation for base models\n",
        ")\n",
        "\n",
        "# Train the Stacking Regressor\n",
        "print(\"Stacking Regressor:\")\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
        "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Define a custom accuracy function for regression\n",
        "def calculate_accuracy(y_true, y_pred, tolerance=0.1):\n",
        "    return (abs(y_true - y_pred) <= tolerance).mean()\n",
        "\n",
        "# Calculate custom accuracy\n",
        "accuracy_stacking = calculate_accuracy(y_test, y_pred_stacking)\n",
        "\n",
        "# Output results\n",
        "print(f'MSE: {mse_stacking}, R^2: {r2_stacking}, Accuracy: {accuracy_stacking}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
