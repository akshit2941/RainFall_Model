{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Neural Network (ANN):\n",
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[4999   22]\n",
      " [  85 2115]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5 features, but StandardScaler is expecting 34 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Example usage of the prediction function\u001b[39;00m\n\u001b[0;32m     70\u001b[0m test_weather_data_1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m25.0\u001b[39m, \u001b[38;5;241m15.0\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m1008\u001b[39m]  \u001b[38;5;66;03m# Replace with actual feature values\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m prediction_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_rainfall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_weather_data_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Case 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m test_weather_data_2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m30.0\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1015\u001b[39m]  \u001b[38;5;66;03m# Replace with actual feature values\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mpredict_rainfall\u001b[1;34m(weather_data)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mPredict if rainfall will occur based on input weather conditions.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m:param weather_data: A list or array of weather features (scaled).\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m:return: \"Rainfall expected\" or \"No rainfall expected\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Scale the input data\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m weather_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweather_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m predicted_rainfall \u001b[38;5;241m=\u001b[39m model_ann\u001b[38;5;241m.\u001b[39mpredict(weather_data_scaled)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_rainfall \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\akshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\akshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1006\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1003\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1005\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1006\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\akshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\akshi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 5 features, but StandardScaler is expecting 34 features as input."
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier  # ANN\n",
    "\n",
    "# Load your dataset (ensure 'Rainfall' is the target variable)\n",
    "data = pd.read_csv('Weather_data.csv')\n",
    "\n",
    "# Create a new 'Rainfall' column from 'precip_mm' if it doesn't exist\n",
    "if 'Rainfall' not in data.columns and 'precip_mm' in data.columns:\n",
    "    data['Rainfall'] = data['precip_mm']\n",
    "elif 'Rainfall' not in data.columns:\n",
    "    raise KeyError(\"'Rainfall' column is missing and 'precip_mm' is also not available. Please check the dataset.\")\n",
    "\n",
    "# Assuming 'Rainfall' is the target variable and binarizing it for classification\n",
    "data['Rainfall'] = data['Rainfall'].apply(lambda x: 1 if x > 0 else 0)  # Binarizing for classification\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)  # Convert categorical variables into dummy/indicator variables\n",
    "\n",
    "# Features and target\n",
    "X = data.drop(columns=['Rainfall'])  # Features\n",
    "y = data['Rainfall']  # Target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling the data (important for ANN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Artificial Neural Network (ANN)\n",
    "print(\"Artificial Neural Network (ANN):\")\n",
    "model_ann = MLPClassifier(max_iter=1000, random_state=42)  # Increase max_iter if needed\n",
    "model_ann.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ann = model_ann.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_ann = accuracy_score(y_test, y_pred_ann)\n",
    "confusion_ann = confusion_matrix(y_test, y_pred_ann)\n",
    "\n",
    "# Output results\n",
    "print(f'Accuracy: {accuracy_ann:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_ann)\n",
    "\n",
    "# Function to predict rainfall based on input weather conditions\n",
    "def predict_rainfall(weather_data):\n",
    "    \"\"\"\n",
    "    Predict if rainfall will occur based on input weather conditions.\n",
    "    \n",
    "    :param weather_data: A list or array of weather features (scaled).\n",
    "    :return: \"Rainfall expected\" or \"No rainfall expected\"\n",
    "    \"\"\"\n",
    "    # Scale the input data\n",
    "    weather_data_scaled = scaler.transform([weather_data])\n",
    "    predicted_rainfall = model_ann.predict(weather_data_scaled)[0]\n",
    "    \n",
    "    if predicted_rainfall == 1:\n",
    "        return \"Rainfall expected\"\n",
    "    else:\n",
    "        return \"No rainfall expected\"\n",
    "\n",
    "# Example usage of the prediction function\n",
    "test_weather_data_1 = [25.0, 15.0, 90, 80, 1008]  # Replace with actual feature values\n",
    "prediction_1 = predict_rainfall(test_weather_data_1)\n",
    "print(f'Test Case 1: {prediction_1}')\n",
    "\n",
    "test_weather_data_2 = [30.0, 10.0, 40, 10, 1015]  # Replace with actual feature values\n",
    "prediction_2 = predict_rainfall(test_weather_data_2)\n",
    "print(f'Test Case 2: {prediction_2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
